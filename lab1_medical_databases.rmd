```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#update.packages(ask = FALSE)

library(readr)          # Data Input
library(rlang)
library(tidymodels)     # Data Manipulation
library(lubridate)      # Data Manupulation
library(dplyr)          # Data Manipulation
library(reshape2)       # Data Manipulation
library(caTools)        # Data Manipulation
library(corrplot)       # Data Visualisation
library(ggplot2)        # Data Visualization
library(viridis)        # Data Visualization
library(ggthemes)       # Data Visualization
library(pROC)           # Metrics
library(caret)          # Machine Learning
library(xgboost)        # xgboost model
```

This practical is based on exploratory data analysis and prediction of a dataset derived from a municipal database of healthcare administrative data. This dataset is derived from Vitoria, the capital city of Espírito Santo, Brazil (population 1.8 million) and was freely shared under a creative commons license.

**Generate an rmarkdown report that contains all the necessary code to document and perform: EDA, prediction of no-shows using XGBoost, and an analysis of variable/feature importance using this data set. Ensure your report includes answers to any questions marked in bold. Please submit your report via brightspace as a link to a git repository containing the rmarkdown and compiled/knitted html version of the notebook.**

## Introduction

The Brazilian public health system, known as SUS for Unified Health System in its acronym in Portuguese, is one of the largest health system in the world, representing government investment of more than 9% of GDP. However, its operation is not homogeneous and there are distinct perceptions of quality from citizens in different regions of the country.  Non-attendance of medical appointments contributes a significant additional burden on limited medical resources.  This analysis will try and investigate possible factors behind non-attendance using an administrative database of appointment data from Vitoria, Espírito Santo, Brazil.

The data required is available via the [course website](https://github.com/maguire-lab/health_data_science_research/tree/master/static_files/practicals/lab1_data).

### Understanding the data

**1** Use the data dictionary describe each of the variables/features in the CSV in your report.

PatientID: Unique identifier for each patient.
AppointmentID: Unique identifier for each appointment.
Gender: Gender of the patient.
ScheduledDay: The day the appointment was scheduled.
AppointmentDay: The day the appointment was set to occur.
Age: Age of the patient.
Neighborhood: The neighborhood of the patient.
Scholarship: Whether the patient is enrolled in the welfare program Bolsa Família.
Hipertension: Whether the patient has hypertension.
Diabetes: Whether the patient has diabetes.
Alcoholism: Whether the patient is an alcoholic.
Handcap: Whether the patient is handicapped.
SMS_received: Whether the patient received a reminder SMS.
No-show: Whether the patient attended the appointment (Yes/No).

**2** Can you think of 3 hypotheses for why someone may be more likely to miss a medical appointment?

Patients with chronic conditions like hypertension and diabetes may be more likely to attend appointments due to the necessity of regular check-ups.
Patients who did not receive a reminder SMS are more likely to miss their appointments.
Patients from neighborhoods with lower socio-economic status may have higher no-show rates due to transportation issues or other socio-economic barriers.

**3** Can you provide 3 examples of important contextual information that is missing in this data dictionary and dataset that could impact your analyses e.g., what type of medical appointment does each `AppointmentID` refer to?  

The type of medical appointment each AppointmentID refers to (e.g., general check-up, specialist visit).
The severity or urgency of the medical condition associated with each appointment.
The exact time of day of the appointment, as appointments at certain times might have higher no-show rates.

## Data Parsing and Cleaning

**4** Modify the following to make it reproducible i.e., downloads the data file directly from version control

```{r parse}
raw.data <- read_csv('2016_05v2_VitoriaAppointmentData.csv', col_types='fffTTifllllflf')
raw.data
#raw.data <- readr::read_csv('https://raw.githubusercontent.com/maguire-lab/health_data_science_research_2024/ ... ')
```

Now we need to check data is valid: because we specified col_types and the data parsed without error most of our data seems to at least be formatted as we expect i.e., ages are integers

```{r}
raw.data %>% filter(Age > 110)
raw.data %>% filter(Age < 0)
```
We can see there are 2 patient's older than 110 which seems suspicious but we can't actually say if this is impossible.

**5** Are there any individuals with impossible ages? If so we can drop this row using `filter` i.e., `data <- data %>% filter(CRITERIA)`
```{r}
cleaned_data <- raw.data %>%
  filter(Age >= 0 & Age <= 110)
summary(cleaned_data$Age)

```

## Exploratory Data Analysis
First, we should get an idea if the data meets our expectations, there are newborns in the data (`Age==0`) and we wouldn't expect any of these to be diagnosed with Diabetes, Alcohol Use Disorder, and Hypertension (although in theory it could be possible).  We can easily check this:

```{r}
raw.data %>% filter(Age == 0) %>% select(Hypertension, Diabetes, AlcoholUseDisorder) %>% unique()
```

We can also explore things like how many different neighborhoods are there and how many appoints are from each? 

```{r}
count(raw.data, Neighbourhood, sort = TRUE)
```
**6** What is the maximum number of appointments from the same patient?

```{r}
patient_appointments <- raw.data %>%
  group_by(PatientID) %>%
  summarise(appointment_count = n())
max_appointments <- max(patient_appointments$appointment_count)
max_appointments

```



Let's explore the correlation between variables:

```{r}

# let's define a plotting function
corplot = function(df){
  
  cor_matrix_raw <- round(cor(df),2)
  cor_matrix <- melt(cor_matrix_raw)
  
  
  #Get triangle of the correlation matrix
  #Lower Triangle
  get_lower_tri<-function(cor_matrix_raw){
    cor_matrix_raw[upper.tri(cor_matrix_raw)] <- NA
    return(cor_matrix_raw)
  }
  
  # Upper Triangle
  get_upper_tri <- function(cor_matrix_raw){
    cor_matrix_raw[lower.tri(cor_matrix_raw)]<- NA
    return(cor_matrix_raw)
  }
  
  upper_tri <- get_upper_tri(cor_matrix_raw)
  
  # Melt the correlation matrix
  cor_matrix <- melt(upper_tri, na.rm = TRUE)
  
  # Heatmap Plot
  cor_graph <- ggplot(data = cor_matrix, aes(Var2, Var1, fill = value))+
    geom_tile(color = "white")+
    scale_fill_gradient2(low = "darkorchid", high = "orangered", mid = "grey50", 
                         midpoint = 0, limit = c(-1,1), space = "Lab", 
                         name="Pearson\nCorrelation") +
    theme_minimal()+ 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                     size = 8, hjust = 1))+
    coord_fixed()+ geom_text(aes(Var2, Var1, label = value), color = "black", size = 2) +
    theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      panel.grid.major = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      axis.ticks = element_blank())+
      ggtitle("Correlation Heatmap")+
      theme(plot.title = element_text(hjust = 0.5))
  
  cor_graph
}

numeric.data = mutate_all(raw.data, function(x) as.numeric(x))

# Plot Correlation Heatmap
corplot(numeric.data)

```

Correlation heatmaps are useful for identifying linear relationships between variables/features.
In this case, we are particularly interested in relationships between `NoShow` and any specific variables.

**7** Which parameters most strongly correlate with missing appointments (`NoShow`)?
No show strongly co-relates with itself.

**8** Are there any other variables which strongly correlate with one another?
Most of the variables strongly correlate with themselves and other variable like Appointment Id has a correlation with patient, Appointment Date has strong correlation with Appointment Id with value 0.65.

**9** Do you see any issues with PatientID/AppointmentID being included in this plot? 

Yes, including PatientID and AppointmentID in the plot is problematic because they are unique identifiers and do not provide meaningful correlation insights. They should be excluded from the analysis.

Let's look at some individual variables and their relationship with `NoShow`.

```{r,fig.align="center"}
ggplot(raw.data) + 
  geom_density(aes(x=Age, fill=NoShow), alpha=0.8) + 
  ggtitle("Density of Age by Attendence")
```
There does seem to be a difference in the distribution of ages of people that miss and don't miss appointments.  
However, the shape of this distribution means the actual correlation is near 0 in the heatmap above. This highlights the need to look at individual variables.

Let's take a closer look at age by breaking it into categories.

```{r, fig.align="center"}
raw.data <- raw.data %>% mutate(Age.Range=cut_interval(Age, length=10))

ggplot(raw.data) + 
  geom_bar(aes(x=Age.Range, fill=NoShow)) + 
  ggtitle("Amount of No Show across Age Ranges")

ggplot(raw.data) + 
  geom_bar(aes(x=Age.Range, fill=NoShow), position='fill') + 
  ggtitle("Proportion of No Show across Age Ranges")

```

**10** How could you be misled if you only plotted 1 of these 2 plots of attendance by age group?
Density Plot:
The density plot shows the overall distribution of ages for those who attend versus those who miss appointments, but it does not reveal specific patterns within age groups. You might miss subtle trends within specific age ranges, such as certain age groups having distinctly higher or lower no-show rates, which might not be apparent in the overall distribution.

Categorized Age Plot:
Categorizing age into groups and plotting attendance might show clearer differences in no-show rates across specific age categories. You might overlook the overall distribution and variability within each age category. For instance, if age groups are too broad, you could miss important nuances, like a peak no-show rate in a very narrow age range that gets averaged out in the categorized plot.

The key takeaway from this is that  number of individuals > 90 are very few from plot 1 so probably are very small so unlikely to make much of an impact on the overall distributions. 
However, other patterns do emerge such as 10-20 age group is nearly twice as likely to miss appointments as the 60-70 years old.

Next, we'll have a look at `SMSReceived` variable:

```{r,fig.align="center"}
ggplot(raw.data) + 
  geom_bar(aes(x=SMSReceived, fill=NoShow), alpha=0.8) + 
  ggtitle("Attendance by SMS Received")

ggplot(raw.data) + 
  geom_bar(aes(x=SMSReceived, fill=NoShow), position='fill', alpha=0.8) + 
  ggtitle("Proportion Attendance by SMS Received")
```


**11** From this plot does it look like SMS reminders increase or decrease the chance of someone not attending an appointment? Why might the opposite actually be true (hint: think about biases)? 

From the plot it does look like when patients are getting reminder  the chance of no show is higher but this cannot concluded that SMS is the reason of no show because
there might be other factors correlated with both receiving SMS reminders and showing up for appointments, such as overall patient engagement or accessibility to technology. For example, younger patients might be more likely to receive SMS reminders and also more likely to attend appointments, not because of the reminder but due to other factors.


**12** Create a similar plot which compares the the density of `NoShow` across the values of disability 

```{r}
#Insert plot

ggplot(raw.data) + 
  geom_bar(aes(x=Disability, fill=NoShow), alpha=0.8) + 
  ggtitle("Attendance by Disability")

ggplot(raw.data) + 
  geom_bar(aes(x=Disability, fill=NoShow), position='fill', alpha=0.8) + 
  ggtitle("Proportion Attendance by Disability")

```

Now let's look at the neighbourhood data as location can correlate highly with many social determinants of health. 

```{r, fig.align="center"}
ggplot(raw.data) + 
  geom_bar(aes(x=Neighbourhood, fill=NoShow)) + 
  theme(axis.text.x = element_text(angle=45, hjust=1, size=5)) + 
  ggtitle('Attendance by Neighbourhood')


ggplot(raw.data) + 
  geom_bar(aes(x=Neighbourhood, fill=NoShow), position='fill') + 
  theme(axis.text.x = element_text(angle=45, hjust=1, size=5)) + 
  ggtitle('Proportional Attendance by Neighbourhood')
```

Most neighborhoods have similar proportions of no-show but some have much higher and lower rates.

**13** Suggest a reason for differences in attendance rates across neighbourhoods.
Socioeconomic Status (SES):
Neighborhoods with lower socioeconomic status might have higher rates of no-shows due to barriers such as lack of transportation, financial constraints, or competing priorities.
Access to Healthcare:
Neighborhoods with limited access to healthcare facilities or services may experience higher rates of no-shows due to difficulty in accessing appointments.

Now let's explore the relationship between gender and NoShow.
```{r, fig.align="center"}
ggplot(raw.data) + 
  geom_bar(aes(x=Gender, fill=NoShow))+
  ggtitle("Gender by attendance")

ggplot(raw.data) + 
  geom_bar(aes(x=Gender, fill=NoShow), position='fill')+
  ggtitle("Proportion Gender by attendance")

```

**14** Create a similar plot using `SocialWelfare`

```{r ,fig.align="center"}
#Insert plot
ggplot(raw.data) + 
  geom_bar(aes(x=SocialWelfare, fill=NoShow)) + 
  theme(axis.text.x = element_text(angle=45, hjust=1, size=5)) + 
  ggtitle('Attendance by SocialWelfare')


ggplot(raw.data) + 
  geom_bar(aes(x=SocialWelfare, fill=NoShow), position='fill') + 
  theme(axis.text.x = element_text(angle=45, hjust=1, size=5)) + 
  ggtitle('Proportional Attendance by SocialWelfare')
```

Far more exploration could still be done, including dimensionality reduction approaches but although we have found some patterns there is no major/striking patterns on the data as it currently stands.

However, maybe we can generate some new features/variables that more strongly relate to the `NoShow`.

## Feature Engineering

Let's begin by seeing if appointments on any day of the week has more no-show's. Fortunately, the `lubridate` library makes this quite easy!

```{r}
raw.data <- raw.data %>% mutate(AppointmentDay = wday(AppointmentDate, label=TRUE, abbr=TRUE), 
                                 ScheduledDay = wday(ScheduledDate,  label=TRUE, abbr=TRUE))

ggplot(raw.data) +
  geom_bar(aes(x=AppointmentDay, fill=NoShow)) +
  ggtitle("Amount of No Show across Appointment Day") 

ggplot(raw.data) +
  geom_bar(aes(x=AppointmentDay, fill=NoShow), position = 'fill') +
  ggtitle("Proportion of No Show across Appointment Day") 

```
Let's begin by creating a variable called `Lag`, which is the difference between when an appointment was scheduled and the actual appointment.

```{r, fig.align="center"}
raw.data <- raw.data %>% mutate(Lag.days=difftime(AppointmentDate, ScheduledDate, units = "days"),
                                Lag.hours=difftime(AppointmentDate, ScheduledDate, units = "hours"))

ggplot(raw.data) + 
  geom_density(aes(x=Lag.days, fill=NoShow), alpha=0.7)+
  ggtitle("Density of Lag (days) by attendance")
```

**15** Have a look at the values in lag variable, does anything seem odd?

Looking at the values in the lag variable, it seems odd that there might be negative values or very large positive values. Negative values would imply that appointments were scheduled after they occurred, which is unlikely. 

## Predictive Modeling

Let's see how well we can predict NoShow from the data. 

We'll start by preparing the data, followed by splitting it into testing and training set, modeling and finally, evaluating our results. For now we will subsample but please run on full dataset for final execution.

```{r}
### REMOVE SUBSAMPLING FOR FINAL MODEL
data.prep <- raw.data %>% select(-AppointmentID, -PatientID) #%>% sample_n(10000)

set.seed(42)
data.split <- initial_split(data.prep, prop = 0.7)
train  <- training(data.split)
test <- testing(data.split)
```

Let's now set the cross validation parameters, and add classProbs so we can use AUC as a metric for xgboost.

```{r}
fit.control <- trainControl(method="cv",number=3,
                           classProbs = TRUE, summaryFunction = twoClassSummary)
```

**16** Based on the EDA, how well do you think this is going to work?

the predictive performance of the model might vary. Addressing class imbalance, selecting informative features, handling data quality issues, capturing complex relationships, incorporating temporal dynamics, and optimizing model selection and tuning are essential steps to improve the model's effectiveness in predicting appointment attendance.

Now we can train our XGBoost model
```{r}
xgb.grid <- expand.grid(eta=c(0.05),
                       max_depth=c(4),colsample_bytree=1,
                       subsample=1, nrounds=500, gamma=0, min_child_weight=5)

xgb.model <- train(NoShow ~ .,data=train, method="xgbTree",metric="ROC",
                  tuneGrid=xgb.grid, trControl=fit.control)

xgb.pred <- predict(xgb.model, newdata=test)
xgb.probs <- predict(xgb.model, newdata=test, type="prob")
```

```{r}
test <- test %>% mutate(NoShow.numerical = ifelse(NoShow=="Yes",1,0))
confusionMatrix(xgb.pred, test$NoShow, positive="Yes")
paste("XGBoost Area under ROC Curve: ", round(auc(test$NoShow.numerical, xgb.probs[,2]),3), sep="")
```

This isn't an unreasonable performance, but let's look a bit more carefully at the correct and incorrect predictions,

```{r ,fig.align="center"}
xgb.probs$Actual = test$NoShow.numerical
xgb.probs$ActualClass = test$NoShow
xgb.probs$PredictedClass = xgb.pred
xgb.probs$Match = ifelse(xgb.probs$ActualClass == xgb.probs$PredictedClass,
                         "Correct","Incorrect")
# [4.8] Plot Accuracy
xgb.probs$Match = factor(xgb.probs$Match,levels=c("Incorrect","Correct"))
ggplot(xgb.probs,aes(x=Yes,y=Actual,color=Match))+
  geom_jitter(alpha=0.2,size=0.25)+
  scale_color_manual(values=c("grey40","orangered"))+
  ggtitle("Visualizing Model Performance", "(Dust Plot)")
```


Finally, let's close it off with the variable importance of our model:

```{r,fig.align="center"}
results = data.frame(Feature = rownames(varImp(xgb.model)$importance)[1:10],
                     Importance = varImp(xgb.model)$importance[1:10,])

results$Feature = factor(results$Feature,levels=results$Feature)


# [4.10] Plot Variable Importance
ggplot(results, aes(x=Feature, y=Importance,fill=Importance))+
  geom_bar(stat="identity")+
  scale_fill_gradient(low="grey20",high="orangered")+
  ggtitle("XGBoost Variable Importance")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**17** Using the [caret package](https://topepo.github.io/caret/) fit and evaluate 1 other ML model on this data.

```{r}
# Load necessary libraries
library(caret)

### REMOVE SUBSAMPLING FOR FINAL MODEL
data.prep <- raw.data %>% select(-AppointmentID, -PatientID) 

set.seed(42)
data.split <- initial_split(data.prep, prop = 0.7)
train  <- training(data.split)
test <- testing(data.split)
fit.control <- trainControl(method="cv", number=3,
                            classProbs = TRUE, summaryFunction = twoClassSummary)
# Train the Random Forest model
rf.grid <- expand.grid(mtry = 2)  

rf.model <- train(NoShow ~ ., data=train, method="rf", metric="ROC",
                  tuneGrid=rf.grid, trControl=fit.control)

# Predict on the test set
rf.pred <- predict(rf.model, newdata=test)
rf.probs <- predict(rf.model, newdata=test, type="prob")

# Create NoShow.numerical column in test set
test <- test %>% mutate(NoShow.numerical = ifelse(NoShow=="Yes",1,0))

# Evaluate the model
confusionMatrix(rf.pred, test$NoShow, positive="Yes")
paste("Random Forest Area under ROC Curve: ", round(auc(test$NoShow.numerical, rf.probs[,2]), 3), sep="")

# Variable importance for Random Forest model
rf.varImp <- varImp(rf.model, scale=FALSE)
rf.results <- data.frame(Feature = rownames(rf.varImp$importance)[1:10],
                         Importance = rf.varImp$importance[1:10,])

rf.results$Feature = factor(rf.results$Feature, levels=rf.results$Feature)

# Plot Variable Importance
ggplot(rf.results, aes(x=Feature, y=Importance, fill=Importance)) +
  geom_bar(stat="identity") +
  scale_fill_gradient(low="grey20", high="orangered") +
  ggtitle("Random Forest Variable Importance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```


**18** Based on everything, do you think we can trust analyses based on this dataset? Explain your reasoning.

While the dataset offers valuable insights and a solid foundation for analysis, it has limitations such as data quality issues, missing contextual information, and potential biases. These factors mean that while the results are informative, they should be interpreted with caution. Ensuring thorough data cleaning, addressing class imbalance, and incorporating additional features could enhance the reliability of the findings. Overall, the analyses are useful but should be treated as preliminary insights rather than definitive conclusions.


## Credits

This notebook was based on a combination of other notebooks e.g., [1](https://www.kaggle.com/code/tsilveira/applying-heatmaps-for-categorical-data-analysis), [2](https://www.kaggle.com/code/samratp/predict-show-noshow-eda-visualization-model), [3](https://www.kaggle.com/code/andrewmvd/exploring-and-predicting-no-shows-with-xgboost/report)