---
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
There are 3-4 packages you will need to install for today's practical: `install.packages(c("xgboost", "eegkit", "forecast", "tseries", "caret"))` apart from that everything else should already be available on your system. 

If you are using a newer Mac you may have to also install [quartz](https://www.xquartz.org/) to have everything work (do this if you see errors about `X11` during install/execution).

I will endeavour to use explicit imports to make it clear where functions are coming from (functions without `library_name::` are part of base R or a function we've defined in this notebook).

```{r libraries, echo=FALSE}
# Using the same library we used earlier in the course for tabular data because we know it works!
library(xgboost)

# EEG manipulation library in R (although very limited compared to signal processing libraries available in other languages, matlab might actually still be a leader in this specific area)
library(eegkit)

# some time series functions (that we only skim the depths of)
library(forecast)
library(tseries)
library(caret)

# just tidyverse libraries that should already be installed
library(dplyr)
library(reshape2)
library(purrr)
library(ggplot2)
```

## EEG Eye Detection Data

One of the most common types of medical sensor data (and one that we talked about during the lecture) are Electroencephalograms (EEGs).  
These measure mesoscale electrical signals (measured in microvolts) within the brain, which are indicative of a region of neuronal activity.
Typically, EEGs involve an array of sensors (aka channels) placed on the scalp with a high degree of covariance between sensors.

As EEG data can be very large and unwieldy, we are going to use a relatively small/simple dataset today from [this paper](http://ehrai.com/su/pdf/aihls2013.pdf).

This dataset is a 117 second continuous EEG measurement collected from a single person with a device called a "Emotiv EEG Neuroheadset".
In combination with the EEG data collection, a camera was used to record whether person being recorded had their eyes open or closed. 
This was eye status was then manually annotated onto the EEG data with `1` indicated the eyes being closed and `0` the eyes being open.
Measures microvoltages are listed in chronological order with the first measured value at the top of the dataframe.

Let's parse the data directly from the `h2o` library's (which we aren't actually using directly) test data S3 bucket:

```{r parse_data}
eeg_url <- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate_splits.csv"
eeg_data <- read.csv(eeg_url)

# add timestamp
Fs <- 117 / nrow(eeg_data)
eeg_data <- transform(eeg_data, ds = seq(0, 116.99999, by = Fs), eyeDetection = as.factor(eyeDetection))
print(table(eeg_data$eyeDetection))

# split dataset into train, validate, test
eeg_train <- subset(eeg_data, split == 'train', select = -split)
print(table(eeg_train$eyeDetection))

eeg_validate <- subset(eeg_data, split == 'valid', select = -split)
eeg_test <- subset(eeg_data, split == 'test', select = -split)
```

**0** Knowing the `eeg_data` contains 117 seconds of data, inspect the `eeg_data` dataframe and the code above to and determine how many samples per second were taken?

Samples per second = 14980/117 = 128


**1** How many EEG electrodes/sensors were used?
```{r}
colnames(eeg_data)
sensor_columns <- setdiff(colnames(eeg_data), c("split", "ds", "eyeDetection"))
num_sensors <- length(sensor_columns)
```


### Exploratory Data Analysis

Now that we have the dataset and some basic parameters let's begin with the ever important/relevant exploratory data analysis.

First we should check there is no missing data!
```{r check_na}
sum(is.na(eeg_data))
```

Great, now we can start generating some plots to look at this data within the time-domain.

First we use `reshape2::melt()` to transform the `eeg_data` dataset from a wide format to a long format expected by `ggplot2`.

Specifically, this converts from "wide" where each electrode has its own column, to a "long" format, where each observation has its own row. 
This format is often more convenient for data analysis and visualization, especially when dealing with repeated measurements or time-series data.

We then use `ggplot2` to create a line plot of electrode intensities per sampling time, with the lines coloured by electrode, and the eye status annotated using dark grey blocks.

```{r plot_data}
melt <- reshape2::melt(eeg_data %>% dplyr::select(-split), id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")


ggplot2::ggplot(melt, ggplot2::aes(x=ds, y=microvolts, color=Electrode)) + 
  ggplot2::geom_line() + 
  ggplot2::ylim(3500,5000) + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(melt, eyeDetection==1), alpha=0.005)
```

**2** Do you see any obvious patterns between eyes being open (dark grey blocks in the plot) and the EEG intensities?

Amplitude Differences: There appear to be variations in the amplitude of the EEG signals when the eyes are closed compared to when they are open. The signals generally show increased amplitude during the periods of eye closure (dark grey blocks).
Consistent Patterns Across Electrodes: Many electrodes has consistent changes in the EEG signal when the eyes are closed. 
Distinct Episodes: The dark grey blocks (indicating eyes closed) correspond to more pronounced and synchronized changes in EEG There are shifts in the baseline of some channels, which might be indicative of different levels of neuronal activity or noise artifacts.


**3** Similarly, based on the distribution of eye open/close state over time to anticipate any temporal correlation between these states?

```{r}
ggplot2::ggplot(eeg_data, ggplot2::aes(x = ds, y = as.numeric(eyeDetection))) + 
  ggplot2::geom_line() + 
  ggplot2::labs(x = "Time (seconds)", y = "Eye State (0=open, 1=closed)") + 
  ggplot2::ggtitle("Eye State Over Time")
eye_state_numeric <- as.numeric(eeg_data$eyeDetection) - 1  # convert factor to numeric
acf_result <- acf(eye_state_numeric, lag.max = 100, plot = TRUE)

```
ACF Plot: Peaks at regular intervals in the ACF plot suggest periodicity. If the ACF decays slowly, it indicates that past values have a lasting influence on future values (positive correlation). If it oscillates, there might be a periodic pattern.

Let's see if we can directly look at the distribution of EEG intensities and see how they related to eye status.


As there are a few extreme outliers in voltage we will use the `dplyr::filter` function to remove values outwith of 3750 to 50003. The function uses the `%in%` operator to check if each value of microvolts is within that range. The function also uses the `dplyr::mutate()` to change the type of the variable eyeDetection from numeric to a factor (R's categorical variable type).

```{r compare_distrib}
melt_train <- reshape2::melt(eeg_train, id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")

# filter huge outliers in voltage
filt_melt_train <- dplyr::filter(melt_train, microvolts %in% (3750:5000)) %>% dplyr::mutate(eyeDetection=as.factor(eyeDetection))

ggplot2::ggplot(filt_melt_train, ggplot2::aes(y=Electrode, x=microvolts, fill=eyeDetection)) + ggplot2::geom_boxplot()
```



Plots are great but sometimes so it is also useful to directly look at the summary statistics and how they related to eye status.
We will do this by grouping the data based on eye status and electrode before calculating the statistics using the convenient `dplyr::summarise` function.

```{r compare_summary_stats}
filt_melt_train %>% dplyr::group_by(eyeDetection, Electrode) %>% 
    dplyr::summarise(mean = mean(microvolts), median=median(microvolts), sd=sd(microvolts)) %>% 
    dplyr::arrange(Electrode)
```




**4** Based on these analyses are any electrodes consistently more intense or varied when eyes are open?
electrodes consistnently showing either higher intensity or variability (standard deviation) when eyes are open are:
AF3
F3
T7
O2
P8
FC6
F4
F8
#### Time-Related Trends

As it looks like there may be a temporal pattern in the data we should investigate how it changes over time.  

First we will do a statistical test for stationarity:

```{r convert_to_tseries}
apply(eeg_train, 2, tseries::adf.test)
```


**5** What is stationarity?
ADF test is used to test for stationarity in each variable (electrodes, eye detection, and "ds" variable) of the EEG data. The null hypothesis of the ADF test is that the time series has a unit root, indicating non-stationarity, while the alternative hypothesis is that the series is stationary. A low p-value (typically below a significance level, often 0.05) suggests rejecting the null hypothesis in favor of stationarity.

Based on the ADF test results, all variables except for the "ds" variable show evidence of stationarity, as indicated by the low p-values. Therefore, the EEG data for the electrodes and eye detection appear to exhibit stationary behavior, which means their statistical properties do not significantly change over time.

**6** Why are we interested in stationarity? What do the results of these tests tell us? (ignoring the lack of multiple comparison correction...)

Stationary time series allow for more straightforward interpretation of statistical measures such as mean, variance, and autocorrelation. Changes in these measures over time can indicate real shifts in the underlying process rather than artifacts of non-stationarity.
The variables (electrodes and eye detection) showing evidence of stationarity suggest that their statistical properties remain consistent over time. This stability allows for reliable analysis and interpretation of these variables without concerns about evolving patterns or trends.

The results of the ADF tests tell us that most of the EEG channels are stationary (p-value = 0.01), meaning their properties are stable over time. However, the time variable ('ds') is non-stationary (p-value = 0.4045), which is expected as time itself progresses and is not constant.

Then we may want to visually explore patterns of autocorrelation (previous values predict future ones) and cross-correlation (correlation across channels over time) using `forecast::ggAcf` function.

The ACF plot displays the cross- and auto-correlation values for different lags (i.e., time delayed versions of each electrode's voltage timeseries) in the dataset. 
It helps identify any significant correlations between channels and observations at different time points. 
Positive autocorrelation indicates that the increase in voltage observed in a given time-interval leads to a proportionate increase in the lagged time interval as well.
Negative autocorrelation indicates the opposite!


```{r correlation}
forecast::ggAcf(eeg_train %>% dplyr::select(-ds))
```


**7** Do any fields show signs of strong autocorrelation (diagonal plots)? Do any pairs of fields show signs of cross-correlation? Provide examples.
Channels such as F7, F3, FC5, and several others show strong signs of positive autocorrelation.
eyeDetection shows strong autocorrelation, suggesting that the state of the eyes (open or closed) has a consistent pattern over time.
F3 and F4, FC5 and FC6, and other adjacent or similarly positioned electrodes might show cross-correlation due to their physical proximity on the scalp and the similar brain activity they measure.

#### Frequency-Space 

We can also explore the data in frequency space by using a Fast Fourier Transform.  
After the FFT we can summarise the distributions of frequencies by their density across the power spectrum.
This will let us see if there any obvious patterns related to eye status in the overall frequency distributions.

```{r fft_open}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 0) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Open")
```

```{r fft_closed}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 1) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Closed")
```
**8** Do you see any differences between the power spectral densities for the two eye states? If so, describe them.

Eyes Closed: Higher power in the lower frequency range, indicating more prominent alpha wave activity.

Eyes Open: More uniform power distribution with generally lower power levels, indicating reduced alpha wave activity.

#### Independent Component Analysis

We may also wish to explore whether there are multiple sources of neuronal activity being picked up by the sensors.  
This can be achieved using a process known as independent component analysis (ICA) which decorrelates the channels and identifies the primary sources of signal within the decorrelated matrix.

```{r ica, warning=FALSE}
ica <- eegkit::eegica(eeg_train %>% dplyr::select(-eyeDetection, -ds), nc=3, method='fast', type='time')
mix <- dplyr::as_tibble(ica$M)
mix$eyeDetection <- eeg_train$eyeDetection
mix$ds <- eeg_train$ds

mix_melt <- reshape2::melt(mix, id.vars=c("eyeDetection", "ds"), variable.name = "Independent Component", value.name = "M")


ggplot2::ggplot(mix_melt, ggplot2::aes(x=ds, y=M, color=`Independent Component`)) + 
  ggplot2::geom_line() + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(mix_melt, eyeDetection==1), alpha=0.005) +
  ggplot2::scale_y_log10()
```



**9** Does this suggest eye opening relates to an independent component of activity across the electrodes?


Yes, the ICA analysis suggests that eye opening relates to an independent component of activity across the electrodes. The plotted independent components show distinct patterns when eyes are open, indicated by vertical lines and changes in the activity levels, which signifies that specific sources of neuronal activity are correlated with the eye status.

### Eye Opening Prediction

Now that we've explored the data let's use a simple model to see how well we can predict eye status from the EEGs:

```{r xgboost}
# Convert the training and validation datasets to matrices
eeg_train_matrix <- as.matrix(dplyr::select(eeg_train, -eyeDetection, -ds))
eeg_train_labels <- as.numeric(eeg_train$eyeDetection) -1

eeg_validate_matrix <- as.matrix(dplyr::select(eeg_validate, -eyeDetection, -ds))
eeg_validate_labels <- as.numeric(eeg_validate$eyeDetection) -1

# Build the xgboost model
model <- xgboost(data = eeg_train_matrix, 
                 label = eeg_train_labels,
                 nrounds = 100,
                 max_depth = 4,
                 eta = 0.1,
                 objective = "binary:logistic")

print(model)
```



**10** Using the `caret` library (or any other library/model type you want such as a naive Bayes) fit another model to predict eye opening.

```{r model2}
library(caret)
library(randomForest)
# Prepare training and validation datasets
eeg_train_data <- eeg_train %>% dplyr::select(-ds)
eeg_validate_data <- eeg_validate %>% dplyr::select(-ds)

# Convert eyeDetection to a factor for classification
eeg_train_data$eyeDetection <- as.factor(eeg_train_data$eyeDetection)
eeg_validate_data$eyeDetection <- as.factor(eeg_validate_data$eyeDetection)

# Set up the train control for cross-validation
train_control <- trainControl(method = "cv", number = 5)

# Train the random forest model
set.seed(123)
rf_model <- train(eyeDetection ~ ., data = eeg_train_data, 
                  method = "rf", 
                  trControl = train_control)

# Print the model summary
print(rf_model)
# Predict on the validation data
rf_predictions <- predict(rf_model, eeg_validate_data)

# Calculate confusion matrix and accuracy
confusion_matrix <- confusionMatrix(rf_predictions, eeg_validate_data$eyeDetection)
print(confusion_matrix)

# Print overall accuracy
accuracy <- confusion_matrix$overall['Accuracy']
print(accuracy)


```


**11** Using the best performing of the two models (on the validation dataset) calculate and report the test performance (filling in the code below):

```{r test}
library(caret)
library(xgboost)
library(randomForest)

eeg_train_data <- eeg_train %>% dplyr::select(-ds)
eeg_validate_data <- eeg_validate %>% dplyr::select(-ds)

eeg_train_data$eyeDetection <- as.factor(eeg_train_data$eyeDetection)
eeg_validate_data$eyeDetection <- as.factor(eeg_validate_data$eyeDetection)

eeg_train_matrix <- as.matrix(dplyr::select(eeg_train, -eyeDetection, -ds))
eeg_train_labels <- as.numeric(eeg_train$eyeDetection) - 1

eeg_validate_matrix <- as.matrix(dplyr::select(eeg_validate, -eyeDetection, -ds))
eeg_validate_labels <- as.numeric(eeg_validate$eyeDetection) - 1

xgb_model <- xgboost(data = eeg_train_matrix, 
                     label = eeg_train_labels,
                     nrounds = 100,
                     max_depth = 4,
                     eta = 0.1,
                     objective = "binary:logistic")

xgb_predictions <- predict(xgb_model, eeg_validate_matrix)
xgb_predictions <- ifelse(xgb_predictions > 0.5, 1, 0)

xgb_confusion_matrix <- confusionMatrix(as.factor(xgb_predictions), as.factor(eeg_validate_labels))
xgb_accuracy <- xgb_confusion_matrix$overall['Accuracy']
print(xgb_accuracy)

train_control <- trainControl(method = "cv", number = 5)

set.seed(123)
rf_model <- train(eyeDetection ~ ., data = eeg_train_data, 
                  method = "rf", 
                  trControl = train_control)

rf_predictions <- predict(rf_model, eeg_validate_data)

rf_confusion_matrix <- confusionMatrix(rf_predictions, eeg_validate_data$eyeDetection)
rf_accuracy <- rf_confusion_matrix$overall['Accuracy']
print(rf_accuracy)

# Compare the accuracies and select the best model
if (xgb_accuracy > rf_accuracy) {
  best_model <- xgb_model
  best_predictions <- xgb_predictions
  best_confusion_matrix <- xgb_confusion_matrix
  best_accuracy <- xgb_accuracy
} else {
  best_model <- rf_model
  best_predictions <- rf_predictions
  best_confusion_matrix <- rf_confusion_matrix
  best_accuracy <- rf_accuracy
}

print(best_confusion_matrix)
print(paste("Best model accuracy: ", best_accuracy))

```

**12** Describe 2 possible alternative modeling approaches for prediction of eye opening from EEGs we discussed in the lecture but haven't explored in this notebook.

Hidden Markov Models (HMMs):

These models describe the data as resulting from a series of hidden states, where the observed EEG values are derived from these hidden states. The transitions between states follow the Markov property, meaning only the previous state(s) matter. HMMs are well-suited for classification and detection tasks in time-series data, making them a potential method for predicting eye opening based on EEG signals

Gaussian Processes:
This non-parametric Bayesian approach models the data by defining a distribution over all possible functions consistent with the observed data. Gaussian Processes are characterized by a covariance kernel, which can capture time, frequency, and state-space models. They provide a flexible framework for predicting complex patterns in EEG data, such as those associated with eye opening​.


**13** What are 2 R libraries you could use to implement these approaches? (note: you don't actually have to implement them though!)
HMMs -
depmixS4: This package allows for the estimation and modeling of hidden Markov models. It supports mixtures of various types of distributions, making it suitable for analyzing EEG data.

Gaussian Processes -
kernlab: This library supports a variety of kernel-based learning methods, including Gaussian Processes for regression and classification.

## Optional

**14** (Optional) As this is the last practical of the course - let me know how you would change future offerings of this course. This will not impact your marks!

- What worked and didn’t work for you (e.g., in terms of the practicals, tutorials, and lectures)?

- Was learning how to run the practicals on your own machines instead of a clean server that will disappear after the course worth the technical challenges?
 
- What would you add or remove from the course? 

- What was the main thing you will take away from this course?